{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "import math\n",
    "import sys\n",
    "import enchant\n",
    "import operator\n",
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(['http://localhost:9200/'])\n",
    "doc = {\n",
    "        'size' : 10000,\n",
    "        'query': {\n",
    "            'match_all' : {}\n",
    "       }\n",
    "   }\n",
    "res = es.search(index='newsgroup', doc_type='document', body=doc,scroll='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "        'size' : 20,\n",
    "        'query': {\n",
    "            'match_all' : {}\n",
    "       }\n",
    "   }\n",
    "res_topics = es.search(index='newsgroup_topic_modelling', body=topics,scroll='1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = res['hits']['hits'][0]['_source']['doc_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = {}\n",
    "topic_words_probs = {}\n",
    "for item in res_topics['hits']['hits']:\n",
    "    id_ = item['_source']['topic_id']\n",
    "    topic_words[id_] = item['_source']['top_words']\n",
    "    topic_words_probs[id_] = item['_source']['word_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentences(doc, doc_topics , topic_words, topic_words_probs):            \n",
    "    sentences = doc.split(\".\")\n",
    "    sentences_score = {}\n",
    "    text = nltk.tokenize.word_tokenize(doc)\n",
    "    for word in text:\n",
    "        if not d.check(word):\n",
    "            if len(word) < 4:\n",
    "                text.remove(word)\n",
    "    for sentence in sentences:\n",
    "        score = 0\n",
    "        words_in_sentence = nltk.tokenize.word_tokenize(sentence)\n",
    "        for word in words_in_sentence:\n",
    "            for topic in topic_words:\n",
    "                if word in topic_words[topic]:\n",
    "                    score += topic_words_probs[topic][topic_words[topic].index(word)]\n",
    "        sentences_score[sentence] = score\n",
    "    return sentences_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}\n",
    "for item in res['hits']['hits']:\n",
    "    sentence_score = score_sentences(item['_source']['doc_text'], \n",
    "                                    item['_source']['doc_topics'],\n",
    "                                    topic_words,\n",
    "                                    topic_words_probs)\n",
    "    sorted_dict = sorted(sentence_score.items(), key=operator.itemgetter(1))[::-1][:10]\n",
    "    summary = \"\"\n",
    "    for sentence in sorted_dict:\n",
    "        summary += sentence[0]        \n",
    "    summaries[item['_source']['doc_id']] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|>The student of \"regional killings\" alias Davidian (not the Davidian religios sect) writes:|>Greater Armenia would stretch from Karabakh, to the Black Sea, to the|>Mediterranean, so if you use the term \"Greater Armenia\" use it with care|>It has always been up to the Azeris to end their announced winning of Karabakh |>by removing the Armenians! When the president of Azerbaijan, Elchibey, came to |>power last year, he announced he would be be \"swimming in Lake Sevan [in |>Armeniaxn] by July\"\\tOr have you changed your calendar???|>Well, he was wrong! If Elchibey is going to shell the |>Armenians of Karabakh from Aghdam, his people will pay the price! If Elchibey \\t\\t\\t\\t\\t\\t    ****************|>is going to shell Karabakh from Fizuli his people will pay the price! If \\t\\t\\t\\t\\t\\t    ******************|>Elchibey thinks he can get away with bombing Armenia from the hills of |>Kelbajar, his people will pay the price Real accurate!Ohhhh so swedish RedCross workers do lie they too? What ever you say\"regional killer\", if you don\\'t like the person then shoot him that\\'s your policy So why search a plane for weapons\\t        since it\\'s content is announced to be weapons?   \\tIf there is one that\\'s confused then that\\'s you! We have the right (and we do)\\tto give weapons to the Azeris, since Armenians started the fight in Azerbadjan! |>You are correct, all Turkish planes should be simply shot down! Nice, slow|>moving air transports!\\tShoot down with what? Armenian bread and butter? Or the arms and personel \\tof the Russian army?\\tThe area will be \"greater\" after some years, like your \"holocaust\" numbers No wonder you are so confused!\\ti\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti\\tConfused?????\\t\\t\\t\\t\\t\\t\\t\\ti\\tYou facist when you delete text don\\'t change it, i wrote:\\t\\ti\\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti        Search Turkish planes? You don\\'t know what you are talking aboutl|>[HE]\\tSearch Turkish planes? You don\\'t know what you are talking about\\t\\tSHALL THE AZERI WOMEN AND CHILDREN GOING TO PAY THE PRICE WITH\\t\\t\\t\\t\\t\\t    **************\\tBEING RAPED, KILLED AND TORTURED BY THE ARMENIANS??????????\\t\\tHAVE YOU HEARDED SOMETHING CALLED: \"GENEVA CONVENTION\"???????\\tYOU FACIST!!!!!\\tOhhh i forgot, this is how Armenians fight, nobody has forgot\\tyou killings, rapings and torture against the Kurds and Turks once\\tupon a time!             |>And anyway, this \"60 |>Kurd refugee\" story, as have other stories, are simple fabrications sourced in |>Baku, modified in Ankara<-------|>[HE]\\tsince it\\'s content is announced to be weapons? \\t\\t\\t\\ti\\t \\t\\t\\t\\t\\t\\t\\t\\t\\t\\ti|>Well, big mouth Ozal said military weapons are being provided to Azerbaijan\\ti|>from Turkey, yet Demirel and others say no'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[\"3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_in_elastic = {}\n",
    "doc_topics_in_elastic = {}\n",
    "kl_summary_in_elastic = {}\n",
    "for item in res['hits']['hits']:\n",
    "    id_ = item['_source']['doc_id']\n",
    "    docs_in_elastic[id_] = item['_source']['doc_text']\n",
    "    doc_topics_in_elastic[id_] = item['_source']['doc_topics']\n",
    "    kl_summary_in_elastic[id_] = item['_source']['kl_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'index': 'newsgroup', 'shards_acknowledged': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# es.indices.delete(index='newsgroup', ignore=[400, 404])\n",
    "mappings_newsgroup = {\n",
    "    'mappings':{\n",
    "        'document':{\n",
    "            'properties':{\n",
    "                'doc_id': {'type': 'text', 'index': 'false'},\n",
    "                'doc_text': {'type': 'text', 'analyzer': 'english'},\n",
    "                'doc_topics':{'type': 'text', 'analyzer': 'english'},\n",
    "                'lda_summary':{'type': 'text', 'analyzer': 'english'},\n",
    "                'kl_summary':{'type': 'text', 'analyzer': 'english'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es.indices.create(index=\"newsgroup\", body=mappings_newsgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for id_ in docs_in_elastic:\n",
    "    docs.append({\n",
    "        'doc_id' : id_,\n",
    "        'doc_text': docs_in_elastic[id_],\n",
    "        'lda_summary' : summaries[id_],\n",
    "        'doc_topics' : doc_topics_in_elastic[id_],\n",
    "        'kl_summary': kl_summary_in_elastic[id_]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    es.index(index='newsgroup', doc_type='document', body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
