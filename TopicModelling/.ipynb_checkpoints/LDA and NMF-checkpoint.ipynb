{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 3.591s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.763s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 0.783s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 0.465s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 2.270s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: people just like time don say really know way things make think right said did want ve probably work years\n",
      "Topic #1: windows thanks using help need hi work know use looking mail software does used pc video available running info advance\n",
      "Topic #2: god does true read know say believe subject says religion mean question point jesus people book christian mind understand matter\n",
      "Topic #3: thanks know like interested mail just want new send edu list does bike thing email reply post wondering hear heard\n",
      "Topic #4: time new 10 year sale old offer 20 16 15 great 30 weeks good test model condition 11 14 power\n",
      "Topic #5: use number com government new university data states information talk phone right including security provide control following long used research\n",
      "Topic #6: edu try file soon remember problem com program hope mike space article wrong library short include win little couldn sun\n",
      "Topic #7: year world team game play won win games season maybe case second does did series playing nhl fact said points\n",
      "Topic #8: think don drive need hard make people mac read going pretty try sure order means trying apple case bit drives\n",
      "Topic #9: just good use way got like ll doesn want sure don doing thought does wrong right better make stuff speed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 6.727s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "tf_feature_probs = tf_vectorizer.max_features\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 14.398s.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit_transform(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0 :  [0.052012955194142743, 0.023301467982437877, 0.018757677200607309, 0.0178530343139022, 0.015950981914168078, 0.014210395836814538, 0.013452740553974224, 0.011952686203526946, 0.011686121720430671, 0.010583275527159298]\n",
      "Topic  1 :  [0.022526318730000262, 0.019200694844516038, 0.016172949248556084, 0.014221316124639097, 0.013672203283395353, 0.012894625646772514, 0.012293395990878954, 0.010477578387284917, 0.01047373254093851, 0.010437073090386346]\n",
      "Topic  2 :  [0.032469056236691086, 0.030531335701190741, 0.023140364283488733, 0.019385890447121058, 0.018174961815483268, 0.013547452168322774, 0.012346358804735584, 0.012129767290121489, 0.011899652878665977, 0.011750142035273158]\n",
      "Topic  3 :  [0.015516269149139042, 0.013378607025368238, 0.013345319294017525, 0.011536459032654708, 0.010955628400982131, 0.010884922758572913, 0.010398867753195951, 0.010017039189285874, 0.0096210481272500543, 0.00959667340055698]\n",
      "Topic  4 :  [0.045386365223251054, 0.043824377248139125, 0.034725327482252155, 0.032023906974168452, 0.029982016318375243, 0.023207250065698685, 0.022038766563193337, 0.018011406473398033, 0.01692268417139178, 0.016334955295514327]\n",
      "Topic  5 :  [0.028927387630506438, 0.020787420495545494, 0.01651888073350084, 0.012383647776586309, 0.010553996990709384, 0.010154237011733626, 0.0092587914102848397, 0.0088025917810353547, 0.0085394102675116854, 0.0084478439352640277]\n",
      "Topic  6 :  [0.036244899086532237, 0.031025866731314158, 0.023371132851261592, 0.017334625820968941, 0.016549562455125736, 0.016477099193474808, 0.016265775698587118, 0.015648430246505831, 0.015464257311821814, 0.014637002583728289]\n",
      "Topic  7 :  [0.033147878167394472, 0.01667497971493925, 0.013580647259594692, 0.012632691772703035, 0.012364674116600758, 0.011969428392882094, 0.011734922267757134, 0.011617683897852971, 0.011018187476231518, 0.010992962541528787]\n",
      "Topic  8 :  [0.028349402183412246, 0.017361347275918346, 0.012759418215518629, 0.012189912307124708, 0.012187553150987926, 0.011355992104509926, 0.010828687871058644, 0.010657804867414295, 0.0087084292941018177, 0.008481283843052051]\n",
      "Topic  9 :  [0.021873213250490048, 0.021159670246099681, 0.014953148884934288, 0.013066710525171754, 0.012551211642513375, 0.011222350615433706, 0.010389261269872403, 0.010139811722503646, 0.0096173149446091254, 0.0094801135264556621]\n"
     ]
    }
   ],
   "source": [
    "lda.components_ /= lda.components_.sum(axis=1)[:, np.newaxis]\n",
    "for i in range(10):\n",
    "    print(\"Topic \",i,\": \", sorted(lda.components_[i])[::-1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
