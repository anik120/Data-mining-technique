{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MNIST dataset\n",
      "Extracting minst_data/train-images-idx3-ubyte.gz\n",
      "Extracting minst_data/train-labels-idx1-ubyte.gz\n",
      "Extracting minst_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting minst_data/t10k-labels-idx1-ubyte.gz\n",
      "Done Loading images as train and test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "print(\"Reading MNIST dataset\")\n",
    "mnist = input_data.read_data_sets('minst_data/')\n",
    "\n",
    "train_images = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_images = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "\n",
    "print(\"Done Loading images as train and test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = list(train_images) + list(test_images)\n",
    "data_Y = np.array(list(train_labels) + list(test_labels))\n",
    "numbers = [0 for x in range(10)]\n",
    "new_images = np.empty((0, 784), int)\n",
    "new_labels = np.empty((0,), int)\n",
    "i = 0\n",
    "new_images = []\n",
    "new_labels = []\n",
    "while(i < len(data_X)):\n",
    "    numbers[data_Y[i]] += 1\n",
    "    if numbers[data_Y[i]] <= 1000:\n",
    "        new_images.append(data_X[i])\n",
    "        new_labels.append(data_Y[i])\n",
    "    i += 1\n",
    "data_X = np.array(new_images)\n",
    "data_Y = np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 10  # number of regions\n",
    "ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ward.fit_predict(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_max_occurences(L):\n",
    "    d = {}\n",
    "    for i in set(L):\n",
    "        d[i] = 0\n",
    "    for i in L:\n",
    "        d[i] += 1\n",
    "    max_value = max(d.values())\n",
    "    max_key = [k for k, v in d.items() if v == max_value]\n",
    "    return max_key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4225\n"
     ]
    }
   ],
   "source": [
    "clusters = {}\n",
    "for i in range(10):\n",
    "    clusters[i] = []\n",
    "\n",
    "for i in range(len(data_X)):\n",
    "    clusters[predictions[i]].append(data_Y[i])\n",
    "purity_count = 0\n",
    "for i in clusters:\n",
    "    max_label = get_max_occurences(list(clusters[i]))\n",
    "    label_count = 0\n",
    "    purity_count += list(clusters[i]).count(max_label)\n",
    "print(purity_count/len(data_X))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
